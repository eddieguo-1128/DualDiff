{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Mmo5y6slBnx2",
        "lECE57Y8BrqH"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "Mmo5y6slBnx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops ema_pytorch mat73 numpy scikit_learn torch tqdm wandb --quiet"
      ],
      "metadata": {
        "id": "BIptPBvHBqBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc67ffa0-aa47-48dc-f332-2875352d89ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/IDL_Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr2NsiZn8Vq2",
        "outputId": "a103b7e8-bcea-4603-860e-a7ed4bf396c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1UTmW6iNsuZDOK5pC8i70YZC-1owajRkF/IDL_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/IDL_Project')"
      ],
      "metadata": {
        "id": "-UrbLS_NVg8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Preprocess Data"
      ],
      "metadata": {
        "id": "lECE57Y8BrqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from DiffE.utils import zscore_norm, EEGDataset\n"
      ],
      "metadata": {
        "id": "ga3u6mv8Bt8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_eeg_data(root_dir, subject_id, data_type='thinking', eeg_channels=None, window_size=256, step_size=128):\n",
        "    subject_id = str(subject_id).zfill(2)\n",
        "    subject_dir = os.path.join(root_dir, subject_id)\n",
        "    file_path = os.path.join(subject_dir, f\"{data_type}.csv\")\n",
        "\n",
        "    df = pd.read_csv(file_path)\n",
        "    if eeg_channels is None:\n",
        "        non_eeg_cols = ['Time:256Hz', 'Epoch', 'Label', 'Stage', 'Flag']\n",
        "        eeg_channels = [col for col in df.columns if col not in non_eeg_cols]\n",
        "\n",
        "    eeg_data = df[eeg_channels].values  # shape: (n_samples, n_channels)\n",
        "    labels = df['Label'].values\n",
        "    unique_labels = np.unique(labels)\n",
        "    label_map = {label: i for i, label in enumerate(unique_labels)}\n",
        "    labels = np.array([label_map[label] for label in labels])\n",
        "\n",
        "    # Reshape data into epochs using sliding windows\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for i in range(0, len(eeg_data) - window_size + 1, step_size):\n",
        "        window_data = eeg_data[i:i+window_size, :].T  # Transpose to get (n_channels, n_timepoints)\n",
        "        window_label = labels[i + window_size // 2]  # Use the label from the middle of the window\n",
        "        X.append(window_data)\n",
        "        Y.append(window_label)\n",
        "\n",
        "    # Convert to torch tensors\n",
        "    X = torch.tensor(np.array(X), dtype=torch.float32)\n",
        "    Y = torch.tensor(np.array(Y), dtype=torch.long)\n",
        "\n",
        "    # Apply z-score normalization\n",
        "    X = zscore_norm(X)\n",
        "\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "OuhF-wWECF9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_multiple_subjects(root_dir, subject_ids, data_type='thinking'):\n",
        "    all_X = []\n",
        "    all_Y = []\n",
        "\n",
        "    for subject_id in subject_ids:\n",
        "        try:\n",
        "            X, Y = load_eeg_data(root_dir, subject_id, data_type)\n",
        "            all_X.append(X)\n",
        "            all_Y.append(Y)\n",
        "            print(f\"Loaded data from subject {subject_id}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data from subject {subject_id}: {e}\")\n",
        "\n",
        "    # Combine data from all subjects\n",
        "    X_combined = torch.cat(all_X, dim=0)\n",
        "    Y_combined = torch.cat(all_Y, dim=0)\n",
        "\n",
        "    return X_combined, Y_combined"
      ],
      "metadata": {
        "id": "5z3S8XYRCQAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_subjects_and_data(root_dir, data_type='thinking', seen_ratio=0.9, train_ratio=0.9, val_ratio=0.15, seed=42):\n",
        "    # Set random seed for reproducibility\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # Get all subject IDs\n",
        "    all_subject_ids = [str(i).zfill(2) for i in range(1, 22)]\n",
        "\n",
        "    # Randomly shuffle subjects\n",
        "    random.shuffle(all_subject_ids)\n",
        "\n",
        "    # Split into seen and unseen\n",
        "    num_seen = int(len(all_subject_ids) * seen_ratio)\n",
        "    seen_subjects = all_subject_ids[:num_seen]\n",
        "    unseen_subjects = all_subject_ids[num_seen:]\n",
        "\n",
        "    print(f\"Seen subjects: {seen_subjects}\")\n",
        "    print(f\"Unseen subjects: {unseen_subjects}\")\n",
        "\n",
        "    # Load data for seen subjects\n",
        "    seen_X, seen_Y = load_multiple_subjects(root_dir, seen_subjects, data_type)\n",
        "\n",
        "    # Split seen subjects' data into train, val, test\n",
        "    train_size = train_ratio\n",
        "    val_size = val_ratio / (1 - train_ratio)  # Adjusted to be relative to remaining data after train split\n",
        "\n",
        "    X_train, X_temp, Y_train, Y_temp = train_test_split(\n",
        "        seen_X, seen_Y, test_size=(1-train_size), random_state=seed, stratify=seen_Y\n",
        "    )\n",
        "\n",
        "    X_val, X_seen_test, Y_val, Y_seen_test = train_test_split(\n",
        "        X_temp, Y_temp, test_size=(1-val_size), random_state=seed, stratify=Y_temp\n",
        "    )\n",
        "\n",
        "    # Load data for unseen subjects (all for testing)\n",
        "    X_unseen_test, Y_unseen_test = load_multiple_subjects(root_dir, unseen_subjects, data_type)\n",
        "\n",
        "    # Create dataloaders\n",
        "    batch_size_train = 32\n",
        "    batch_size_test = 64\n",
        "\n",
        "    train_dataset = EEGDataset(X_train, Y_train)\n",
        "    val_dataset = EEGDataset(X_val, Y_val)\n",
        "    seen_test_dataset = EEGDataset(X_seen_test, Y_seen_test)\n",
        "    unseen_test_dataset = EEGDataset(X_unseen_test, Y_unseen_test)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size_test, shuffle=False)\n",
        "    seen_test_loader = DataLoader(seen_test_dataset, batch_size=batch_size_test, shuffle=False)\n",
        "    unseen_test_loader = DataLoader(unseen_test_dataset, batch_size=batch_size_test, shuffle=False)\n",
        "\n",
        "    print(f\"Train samples: {len(train_dataset)}\")\n",
        "    print(f\"Validation samples: {len(val_dataset)}\")\n",
        "    print(f\"Seen test samples: {len(seen_test_dataset)}\")\n",
        "    print(f\"Unseen test samples: {len(unseen_test_dataset)}\")\n",
        "\n",
        "    return train_loader, val_loader, seen_test_loader, unseen_test_loader"
      ],
      "metadata": {
        "id": "Pd4s5C1qCTYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size_train = 32\n",
        "batch_size_test = 64\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_loader, validation_loader, seen_test_loader, unseen_test_loader = split_subjects_and_data(\n",
        "    root_dir=\"data_eeg\",\n",
        "    data_type='stimuli',\n",
        "    seen_ratio=0.9,  # 18 seen, 3 unseen\n",
        "    train_ratio=0.7,\n",
        "    val_ratio=0.15,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "kJ2xaYbRLcum",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e04efb-d167-4127-fa16-137605414999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seen subjects: ['20', '06', '15', '05', '10', '14', '16', '19', '07', '13', '18', '11', '02', '12', '03', '17', '08', '09']\n",
            "Unseen subjects: ['01', '04', '21']\n",
            "Loaded data from subject 20\n",
            "Loaded data from subject 06\n",
            "Loaded data from subject 15\n",
            "Loaded data from subject 05\n",
            "Loaded data from subject 10\n",
            "Loaded data from subject 14\n",
            "Loaded data from subject 16\n",
            "Loaded data from subject 19\n",
            "Loaded data from subject 07\n",
            "Loaded data from subject 13\n",
            "Loaded data from subject 18\n",
            "Loaded data from subject 11\n",
            "Loaded data from subject 02\n",
            "Loaded data from subject 12\n",
            "Loaded data from subject 03\n",
            "Loaded data from subject 17\n",
            "Loaded data from subject 08\n",
            "Loaded data from subject 09\n",
            "Loaded data from subject 01\n",
            "Loaded data from subject 04\n",
            "Loaded data from subject 21\n",
            "Train samples: 19811\n",
            "Validation samples: 4245\n",
            "Seen test samples: 4246\n",
            "Unseen test samples: 4797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "-cM9P_X_D5or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from einops import reduce"
      ],
      "metadata": {
        "id": "satc0jEEhwpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_padding(kernel_size, dilation=1):\n",
        "    return int((kernel_size * dilation - dilation) / 2)\n",
        "\n",
        "\n",
        "# Swish activation function\n",
        "class Swish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.sigmoid(x)\n",
        "\n",
        "\n",
        "class SinusoidalPosEmb(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        half_dim = self.dim // 2\n",
        "        emb = math.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
        "        emb = x[:, None] * emb[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
        "        return emb\n",
        "\n",
        "\n",
        "class WeightStandardizedConv1d(nn.Conv1d):\n",
        "    \"\"\"\n",
        "    https://arxiv.org/abs/1903.10520\n",
        "    weight standardization purportedly works synergistically with group normalization\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-5 if x.dtype == torch.float32 else 1e-3\n",
        "\n",
        "        weight = self.weight\n",
        "        mean = reduce(weight, \"o ... -> o 1 1\", \"mean\")\n",
        "        var = reduce(weight, \"o ... -> o 1 1\", partial(torch.var, unbiased=False))\n",
        "        normalized_weight = (weight - mean) * (var + eps).rsqrt()\n",
        "\n",
        "        return F.conv1d(\n",
        "            x,\n",
        "            normalized_weight,\n",
        "            self.bias,\n",
        "            self.stride,\n",
        "            self.padding,\n",
        "            self.dilation,\n",
        "            self.groups,\n",
        "        )\n",
        "\n",
        "\n",
        "class ResidualConvBlock(nn.Module):\n",
        "    def __init__(self, inc: int, outc: int, kernel_size: int, stride=1, gn=8):\n",
        "        super().__init__()\n",
        "        \"\"\"\n",
        "        standard ResNet style convolutional block\n",
        "        \"\"\"\n",
        "        self.same_channels = inc == outc\n",
        "        self.ks = kernel_size\n",
        "        self.conv = nn.Sequential(\n",
        "            WeightStandardizedConv1d(inc, outc, self.ks, stride, get_padding(self.ks)),\n",
        "            nn.GroupNorm(gn, outc),\n",
        "            nn.PReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x1 = self.conv(x)\n",
        "        if self.same_channels:\n",
        "            out = (x + x1) / 2\n",
        "        else:\n",
        "            out = x1\n",
        "        return out\n",
        "\n",
        "\n",
        "class UnetDown(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, gn=8, factor=2):\n",
        "        super(UnetDown, self).__init__()\n",
        "        self.pool = nn.MaxPool1d(factor)\n",
        "        self.layer = ResidualConvBlock(in_channels, out_channels, kernel_size, gn=gn)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer(x)\n",
        "        x = self.pool(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UnetUp(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, gn=8, factor=2):\n",
        "        super(UnetUp, self).__init__()\n",
        "        self.pool = nn.Upsample(scale_factor=factor, mode=\"nearest\")\n",
        "        self.layer = ResidualConvBlock(in_channels, out_channels, kernel_size, gn=gn)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        x = self.layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EmbedFC(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim):\n",
        "        super(EmbedFC, self).__init__()\n",
        "        \"\"\"\n",
        "        generic one layer FC NN for embedding things\n",
        "        \"\"\"\n",
        "        self.input_dim = input_dim\n",
        "        layers = [\n",
        "            nn.Linear(input_dim, emb_dim),\n",
        "            nn.PReLU(),\n",
        "            nn.Linear(emb_dim, emb_dim),\n",
        "        ]\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_dim)\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class ConditionalUNet(nn.Module):\n",
        "    def __init__(self, in_channels, n_feat=256):\n",
        "        super(ConditionalUNet, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.n_feat = n_feat\n",
        "\n",
        "        self.d1_out = n_feat * 1\n",
        "        self.d2_out = n_feat * 2\n",
        "        self.d3_out = n_feat * 3\n",
        "        self.d4_out = n_feat * 4\n",
        "\n",
        "        self.u1_out = n_feat\n",
        "        self.u2_out = n_feat\n",
        "        self.u3_out = n_feat\n",
        "        self.u4_out = in_channels\n",
        "\n",
        "        self.sin_emb = SinusoidalPosEmb(n_feat)\n",
        "        # self.timeembed1 = EmbedFC(n_feat, self.u1_out)\n",
        "        # self.timeembed2 = EmbedFC(n_feat, self.u2_out)\n",
        "        # self.timeembed3 = EmbedFC(n_feat, self.u3_out)\n",
        "\n",
        "        self.down1 = UnetDown(in_channels, self.d1_out, 1, gn=2, factor=2)\n",
        "        self.down2 = UnetDown(self.d1_out, self.d2_out, 1, gn=2, factor=2)\n",
        "        self.down3 = UnetDown(self.d2_out, self.d3_out, 1, gn=2, factor=2)\n",
        "\n",
        "        self.up2 = UnetUp(self.d3_out, self.u2_out, 1, gn=2, factor=2)\n",
        "        self.up3 = UnetUp(self.u2_out + self.d2_out, self.u3_out, 1, gn=2, factor=2)\n",
        "        self.up4 = UnetUp(self.u3_out + self.d1_out, self.u4_out, 1, gn=2, factor=2)\n",
        "        self.out = nn.Conv1d(self.u4_out + in_channels, in_channels, 1)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        down1 = self.down1(x)  # 2000 -> 1000\n",
        "        down2 = self.down2(down1)  # 1000 -> 500\n",
        "        down3 = self.down3(down2)  # 500 -> 250\n",
        "\n",
        "        temb = self.sin_emb(t).view(-1, self.n_feat, 1)  # [b, n_feat, 1]\n",
        "\n",
        "        up1 = self.up2(down3)  # 250 -> 500\n",
        "        up2 = self.up3(torch.cat([up1 + temb, down2], 1))  # 500 -> 1000\n",
        "        up3 = self.up4(torch.cat([up2 + temb, down1], 1))  # 1000 -> 2000\n",
        "        out = self.out(torch.cat([up3, x], 1))  # 2000 -> 2000\n",
        "\n",
        "        down = (down1, down2, down3)\n",
        "        up = (up1, up2, up3)\n",
        "        return out, down, up\n",
        "\n",
        "class AttentionPool1d(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(AttentionPool1d, self).__init__()\n",
        "        # Learnable query vector (shape: [in_channels])\n",
        "        self.query = nn.Parameter(torch.randn(in_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: Tensor of shape (B, C, L) where B=batch size, C=channels, L=sequence length\n",
        "        Returns a tensor of shape (B, C) by computing a weighted sum over L.\n",
        "        \"\"\"\n",
        "        B, C, L = x.shape\n",
        "        # Permute x to shape (B, L, C)\n",
        "        x_perm = x.permute(0, 2, 1)  # (B, L, C)\n",
        "        # Compute attention scores as dot-product between each time step and the query vector.\n",
        "        # Resulting scores shape: (B, L)\n",
        "        scores = torch.einsum('blc,c->bl', x_perm, self.query)\n",
        "        # Softmax over the time dimension to get attention weights.\n",
        "        weights = F.softmax(scores, dim=-1)  # (B, L)\n",
        "        # Compute weighted sum over the time dimension.\n",
        "        pooled = torch.sum(x * weights.unsqueeze(1), dim=2)  # (B, C)\n",
        "        return pooled\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels, dim=512):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.e1_out = dim\n",
        "        self.e2_out = dim\n",
        "        self.e3_out = dim\n",
        "\n",
        "        self.down1 = UnetDown(in_channels, self.e1_out, 1, gn=2, factor=2)\n",
        "        self.down2 = UnetDown(self.e1_out, self.e2_out, 1, gn=2, factor=2)\n",
        "        self.down3 = UnetDown(self.e2_out, self.e3_out, 1, gn=2, factor=2)\n",
        "\n",
        "        # self.avg_pooling = nn.AdaptiveAvgPool1d(output_size=1)\n",
        "        self.att_pooling = AttentionPool1d(self.e3_out)\n",
        "        # self.max_pooling = nn.AdaptiveMaxPool1d(output_size=1)\n",
        "        self.act = nn.Tanh()\n",
        "\n",
        "    def forward(self, x0):\n",
        "        # Down sampling\n",
        "        dn1 = self.down1(x0)  # 2048 -> 1024\n",
        "        dn2 = self.down2(dn1)  # 1024 -> 512\n",
        "        dn3 = self.down3(dn2)  # 512 -> 256\n",
        "        # z = self.avg_pooling(dn3).view(-1, self.e3_out)  # [b, features]\n",
        "        z = self.att_pooling(dn3)\n",
        "        down = (dn1, dn2, dn3)\n",
        "        out = (down, z)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, n_feat=256, encoder_dim=512, n_classes=13):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.n_feat = n_feat\n",
        "        self.n_classes = n_classes\n",
        "        self.e1_out = encoder_dim\n",
        "        self.e2_out = encoder_dim\n",
        "        self.e3_out = encoder_dim\n",
        "        self.d1_out = n_feat\n",
        "        self.d2_out = n_feat * 2\n",
        "        self.d3_out = n_feat * 3\n",
        "        self.u1_out = n_feat\n",
        "        self.u2_out = n_feat\n",
        "        self.u3_out = n_feat\n",
        "        self.u4_out = in_channels\n",
        "\n",
        "        # self.sin_emb = SinusoidalPosEmb(n_feat)\n",
        "        # self.timeembed1 = EmbedFC(n_feat, self.e3_out)\n",
        "        # self.timeembed2 = EmbedFC(n_feat, self.u2_out)\n",
        "        # self.timeembed3 = EmbedFC(n_feat, self.u3_out)\n",
        "        # self.contextembed1 = EmbedFC(self.e3_out, self.e3_out)\n",
        "        # self.contextembed2 = EmbedFC(self.e3_out, self.u2_out)\n",
        "        # self.contextembed3 = EmbedFC(self.e3_out, self.u3_out)\n",
        "\n",
        "        # Unet up sampling\n",
        "        self.up1 = UnetUp(self.d3_out + self.e3_out, self.u2_out, 1, gn=2, factor=2)\n",
        "        self.up2 = UnetUp(self.d2_out + self.u2_out, self.u3_out, 1, gn=2, factor=2)\n",
        "        self.up3 = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2, mode=\"nearest\"),\n",
        "            nn.Conv1d(\n",
        "                self.d1_out + self.u3_out + in_channels * 2, in_channels, 1, 1, 0\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # self.out = nn.Conv1d(self.u4_out+in_channels, in_channels, 1)\n",
        "        self.pool = nn.AvgPool1d(2)\n",
        "\n",
        "    def forward(self, x0, encoder_out, diffusion_out):\n",
        "        # Encoder output\n",
        "        down, z = encoder_out\n",
        "        dn1, dn2, dn3 = down\n",
        "\n",
        "        # DDPM output\n",
        "        x_hat, down_ddpm, up, t = diffusion_out\n",
        "        dn11, dn22, dn33 = down_ddpm\n",
        "\n",
        "        # embed context, time step\n",
        "        # temb = self.sin_emb(t).view(-1, self.n_feat, 1) # [b, n_feat, 1]\n",
        "        # temb1 = self.timeembed1(temb).view(-1, self.e3_out, 1) # [b, features]\n",
        "        # temb2 = self.timeembed2(temb).view(-1, self.u2_out, 1) # [b, features]\n",
        "        # temb3 = self.timeembed3(temb).view(-1, self.u3_out, 1) # [b, features]\n",
        "        # ct2 = self.contextembed2(z).view(-1, self.u2_out, 1) # [b, n_feat, 1]\n",
        "        # ct3 = self.contextembed3(z).view(-1, self.u3_out, 1) # [b, n_feat, 1]\n",
        "\n",
        "        # Up sampling\n",
        "        up1 = self.up1(torch.cat([dn3, dn33.detach()], 1))\n",
        "        up2 = self.up2(torch.cat([up1, dn22.detach()], 1))\n",
        "        out = self.up3(\n",
        "            torch.cat([self.pool(x0), self.pool(x_hat.detach()), up2, dn11.detach()], 1)\n",
        "        )\n",
        "        return out\n",
        "\n",
        "\n",
        "class DiffE(nn.Module):\n",
        "    def __init__(self, encoder, decoder, fc):\n",
        "        super(DiffE, self).__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.fc = fc\n",
        "\n",
        "    def forward(self, x0, ddpm_out):\n",
        "        encoder_out = self.encoder(x0)\n",
        "        z = encoder_out[1]\n",
        "        decoder_out = self.decoder(x0, encoder_out, ddpm_out)\n",
        "        fc_out = self.fc(encoder_out[1])\n",
        "        return decoder_out, fc_out, z\n",
        "\n",
        "\n",
        "class DecoderNoDiff(nn.Module):\n",
        "    def __init__(self, in_channels, n_feat=256, encoder_dim=512, n_classes=13):\n",
        "        super(DecoderNoDiff, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.n_feat = n_feat\n",
        "        self.n_classes = n_classes\n",
        "        self.e1_out = encoder_dim\n",
        "        self.e2_out = encoder_dim\n",
        "        self.e3_out = encoder_dim\n",
        "        self.u1_out = n_feat\n",
        "        self.u2_out = n_feat\n",
        "        self.u3_out = n_feat\n",
        "        self.u4_out = n_feat\n",
        "\n",
        "        self.sin_emb = SinusoidalPosEmb(n_feat)\n",
        "        self.timeembed1 = EmbedFC(n_feat, self.e3_out)\n",
        "        self.timeembed2 = EmbedFC(n_feat, self.u2_out)\n",
        "        self.timeembed3 = EmbedFC(n_feat, self.u3_out)\n",
        "        self.contextembed1 = EmbedFC(self.e3_out, self.e3_out)\n",
        "        self.contextembed2 = EmbedFC(self.e3_out, self.u2_out)\n",
        "        self.contextembed3 = EmbedFC(self.e3_out, self.u3_out)\n",
        "\n",
        "        # Unet up sampling\n",
        "        self.up2 = UnetUp(self.e3_out, self.u2_out, 1, gn=2, factor=2)\n",
        "        self.up3 = UnetUp(self.e2_out + self.u2_out, self.u3_out, 1, gn=2, factor=2)\n",
        "        # self.up4 = UnetUp(self.e1_out+self.u3_out, self.u4_out, 1, 1, gn=in_channels, factor=2, is_res=True)\n",
        "        self.up4 = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2, mode=\"nearest\"),\n",
        "            nn.Conv1d(self.u3_out + self.e1_out + in_channels, in_channels, 1, 1, 0),\n",
        "        )\n",
        "\n",
        "        self.out = nn.Conv1d(self.u4_out, in_channels, 1)\n",
        "        self.pool = nn.AvgPool1d(2)\n",
        "\n",
        "    def forward(self, x0, x_hat, encoder_out, t):\n",
        "        down, z = encoder_out\n",
        "        dn1, dn2, dn3 = down\n",
        "        tembd = self.sin_emb(t).view(-1, self.n_feat, 1)  # [b, n_feat, 1]\n",
        "        tembd1 = self.timeembed1(self.sin_emb(t)).view(\n",
        "            -1, self.e3_out, 1\n",
        "        )  # [b, n_feat, 1]\n",
        "        tembd2 = self.timeembed2(self.sin_emb(t)).view(\n",
        "            -1, self.u2_out, 1\n",
        "        )  # [b, n_feat, 1]\n",
        "        tembd3 = self.timeembed3(self.sin_emb(t)).view(\n",
        "            -1, self.u3_out, 1\n",
        "        )  # [b, n_feat, 1]\n",
        "\n",
        "        # Up sampling\n",
        "        ddpm_loss = F.l1_loss(x0, x_hat, reduction=\"none\")\n",
        "\n",
        "        up2 = self.up2(dn3)  # 256 -> 512\n",
        "        up3 = self.up3(torch.cat([up2, dn2], 1))  # 512 -> 1024\n",
        "        out = self.up4(\n",
        "            torch.cat([self.pool(x0), self.pool(x_hat), up3, dn1], 1)\n",
        "        )  # 1024 -> 2048\n",
        "        # out = self.out(torch.cat([out, x_hat], 1)) # 2048 -> 2048\n",
        "        # out = self.out(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class LinearClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, latent_dim, emb_dim):\n",
        "        super().__init__()\n",
        "        self.linear_out = nn.Sequential(\n",
        "            nn.Linear(in_features=in_dim, out_features=latent_dim),\n",
        "            nn.GroupNorm(4, latent_dim),\n",
        "            nn.PReLU(),\n",
        "            nn.Linear(in_features=latent_dim, out_features=latent_dim),\n",
        "            nn.GroupNorm(4, latent_dim),\n",
        "            nn.PReLU(),\n",
        "            nn.Linear(in_features=latent_dim, out_features=emb_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear_out(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def cosine_beta_schedule(timesteps, s=0.008):\n",
        "    \"\"\"\n",
        "    cosine schedule\n",
        "    as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n",
        "    \"\"\"\n",
        "    steps = timesteps + 1\n",
        "    t = torch.linspace(0, timesteps, steps, dtype=torch.float64) / timesteps\n",
        "    alphas_cumprod = torch.cos((t + s) / (1 + s) * math.pi * 0.5) ** 2\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return torch.clip(betas, 0, 0.999)\n",
        "\n",
        "\n",
        "def sigmoid_beta_schedule(timesteps, start=-3, end=3, tau=1, clamp_min=1e-5):\n",
        "    \"\"\"\n",
        "    sigmoid schedule\n",
        "    proposed in https://arxiv.org/abs/2212.11972 - Figure 8\n",
        "    \"\"\"\n",
        "    steps = timesteps + 1\n",
        "    t = torch.linspace(0, timesteps, steps, dtype=torch.float64) / timesteps\n",
        "    v_start = torch.tensor(start / tau).sigmoid()\n",
        "    v_end = torch.tensor(end / tau).sigmoid()\n",
        "    alphas_cumprod = (-((t * (end - start) + start) / tau).sigmoid() + v_end) / (\n",
        "        v_end - v_start\n",
        "    )\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return torch.clip(betas, 0, 0.999)\n",
        "\n",
        "\n",
        "def ddpm_schedules(beta1, beta2, T):\n",
        "    # assert beta1 < beta2 < 1.0, \"beta1 and beta2 must be in (0, 1)\"\n",
        "    # beta_t = (beta2 - beta1) * torch.arange(0, T + 1, dtype=torch.float32) / T + beta1\n",
        "    beta_t = cosine_beta_schedule(T, s=0.008).float()\n",
        "    # beta_t = sigmoid_beta_schedule(T).float()\n",
        "\n",
        "    alpha_t = 1 - beta_t\n",
        "\n",
        "    log_alpha_t = torch.log(alpha_t)\n",
        "    alphabar_t = torch.cumsum(log_alpha_t, dim=0).exp()\n",
        "\n",
        "    sqrtab = torch.sqrt(alphabar_t)\n",
        "\n",
        "    sqrtmab = torch.sqrt(1 - alphabar_t)\n",
        "\n",
        "    return {\n",
        "        \"sqrtab\": sqrtab,  # \\sqrt{\\bar{\\alpha_t}}\n",
        "        \"sqrtmab\": sqrtmab,  # \\sqrt{1-\\bar{\\alpha_t}}\n",
        "    }\n",
        "\n",
        "\n",
        "class DDPM(nn.Module):\n",
        "    def __init__(self, nn_model, betas, n_T, device):\n",
        "        super(DDPM, self).__init__()\n",
        "        self.nn_model = nn_model.to(device)\n",
        "\n",
        "        for k, v in ddpm_schedules(betas[0], betas[1], n_T).items():\n",
        "            self.register_buffer(k, v)\n",
        "\n",
        "        self.n_T = n_T\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, x):\n",
        "        _ts = torch.randint(1, self.n_T, (x.shape[0],)).to(\n",
        "            self.device\n",
        "        )  # t ~ Uniform(0, n_T)\n",
        "        noise = torch.randn_like(x)  # eps ~ N(0, 1)\n",
        "        x_t = self.sqrtab[_ts, None, None] * x + self.sqrtmab[_ts, None, None] * noise\n",
        "        times = _ts / self.n_T\n",
        "        output, down, up = self.nn_model(x_t, times)\n",
        "        return output, down, up, noise, times"
      ],
      "metadata": {
        "id": "lfs6mCx1WzQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 16\n",
        "channels = 14\n",
        "n_T = 1000\n",
        "ddpm_dim = 128\n",
        "encoder_dim = 256\n",
        "fc_dim = 512"
      ],
      "metadata": {
        "id": "fv6aN9TvE1ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddpm_model = ConditionalUNet(in_channels=channels, n_feat=ddpm_dim).to(device)\n",
        "ddpm = DDPM(nn_model=ddpm_model, betas=(1e-6, 1e-2), n_T=n_T, device=device).to(device)\n",
        "encoder = Encoder(in_channels=channels, dim=encoder_dim).to(device)\n",
        "decoder = Decoder(in_channels=channels, n_feat=ddpm_dim, encoder_dim=encoder_dim).to(device)\n",
        "fc = LinearClassifier(encoder_dim, fc_dim, emb_dim=num_classes).to(device)\n",
        "diffe = DiffE(encoder, decoder, fc).to(device)"
      ],
      "metadata": {
        "id": "08kpz17EE6nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ddpm size: \", sum(p.numel() for p in ddpm.parameters()))\n",
        "print(\"encoder size: \", sum(p.numel() for p in encoder.parameters()))\n",
        "print(\"decoder size: \", sum(p.numel() for p in decoder.parameters()))\n",
        "print(\"fc size: \", sum(p.numel() for p in fc.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhmXU3HtMhlO",
        "outputId": "b28d7534-d41d-48dd-f3a6-ffd45c1cd25b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ddpm size:  238278\n",
            "encoder size:  137219\n",
            "decoder size:  135832\n",
            "fc size:  404498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "qOZsp31dOYxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login(key=\"fc35b6207578f4e85e34481be02780068223a3f6\")\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import tqdm\n",
        "from tqdm.auto import tqdm\n",
        "from ema_pytorch import EMA\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    top_k_accuracy_score,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_XRvshakE9N",
        "outputId": "177918d8-d492-48d8-881e-fa3136fff5b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criterion\n",
        "criterion = nn.L1Loss(reduction='none')\n",
        "criterion_class = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ZJUYGayjM6JQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_ddpm = 1e-4\n",
        "lr_diffe = 1e-4\n",
        "weight_decay = 0.01\n",
        "\n",
        "optimizer1 = optim.AdamW(ddpm.parameters(), lr=lr_ddpm, weight_decay=weight_decay)\n",
        "optimizer2 = optim.AdamW(diffe.parameters(), lr=lr_diffe, weight_decay=weight_decay)"
      ],
      "metadata": {
        "id": "PLXqU6jxndof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "scheduler1 = optim.lr_scheduler.CosineAnnealingLR(optimizer1, T_max=num_epochs, eta_min=1e-7)\n",
        "scheduler2 = optim.lr_scheduler.CosineAnnealingLR(optimizer2, T_max=num_epochs, eta_min=1e-7)"
      ],
      "metadata": {
        "id": "X9u-L7A3nhyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc_ema = EMA(diffe.fc, beta=0.95, update_after_step=100, update_every=10)"
      ],
      "metadata": {
        "id": "nVWSHH3FnlNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory for saving models if it doesn't exist\n",
        "models_path = \"saved_models\"\n",
        "os.makedirs(models_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "ZsvEqwyHnnsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_accuracy = 0.0"
      ],
      "metadata": {
        "id": "D2cFi3-Lnp2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SupConLoss(nn.Module):\n",
        "    def __init__(self, temperature=0.07):\n",
        "        super(SupConLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, features, labels):\n",
        "        \"\"\"\n",
        "        features: [B, D] — z output from the encoder\n",
        "        labels:   [B]    — integer type labels\n",
        "        \"\"\"\n",
        "        device = features.device\n",
        "        features = F.normalize(features, dim=1)              # Feature normalization\n",
        "        batch_size = features.shape[0]\n",
        "\n",
        "        # Construct positive sample mask\n",
        "        labels = labels.contiguous().view(-1, 1)\n",
        "        mask = torch.eq(labels, labels.T).float().to(device)  # [B, B], 1 if same class\n",
        "\n",
        "        # Similarity matrix\n",
        "        sim = torch.matmul(features, features.T) / self.temperature  # [B, B]\n",
        "\n",
        "        # Exclude diagonal (self with self)\n",
        "        logits_mask = torch.ones_like(mask) - torch.eye(batch_size).to(device)\n",
        "        mask = mask * logits_mask\n",
        "        sim = sim - 1e9 * (1 - logits_mask)  # Mask the diagonal with large negative value\n",
        "\n",
        "        # Compute log-softmax\n",
        "        exp_sim = torch.exp(sim)\n",
        "        log_prob = sim - torch.log(exp_sim.sum(1, keepdim=True) + 1e-6)\n",
        "\n",
        "        # Compute mean log-probability of positive samples for each instance\n",
        "        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-6)\n",
        "\n",
        "        # Mean negative log-likelihood\n",
        "        loss = -mean_log_prob_pos.mean()\n",
        "        return loss"
      ],
      "metadata": {
        "id": "EmeB3x2NbS-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(self, input_dim=256, proj_dim=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, proj_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(proj_dim, proj_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return F.normalize(self.net(z), dim=1)"
      ],
      "metadata": {
        "id": "4HhOQNILbWZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(ddpm_model, diffe_model, ema_classifier, train_loader,\n",
        "                optimizer1, optimizer2, scheduler1, scheduler2,\n",
        "                criterion_recon, criterion_class, epoch, device, num_classes):\n",
        "    \"\"\"Runs a single training epoch.\"\"\"\n",
        "    ddpm_model.train()\n",
        "    diffe_model.train()\n",
        "\n",
        "    total_loss_supcon = 0.0\n",
        "    total_loss_decoder = 0.0\n",
        "    total_loss_c = 0.0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    alpha = 1\n",
        "    beta = min(1.0, epoch / 50) * 0.2\n",
        "    gamma = min(1.0, epoch / 100) * 0.05\n",
        "    supcon_loss = SupConLoss(temperature=0.07)\n",
        "    proj_head = ProjectionHead(input_dim=256, proj_dim=128).to(device)\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Training\", leave=True)\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(train_loader):\n",
        "        x, y = x.to(device), y.type(torch.LongTensor).to(device)\n",
        "\n",
        "        # --- Train DDPM ---\n",
        "        optimizer1.zero_grad()\n",
        "        x_hat, down, up, noise, t = ddpm_model(x)\n",
        "        # Use the criterion_recon which has reduction='none'\n",
        "        loss_ddpm_per_sample = criterion_recon(x_hat, x)  # No reduction param needed\n",
        "        loss_ddpm = loss_ddpm_per_sample.mean()  # Average for DDPM backward pass\n",
        "        loss_ddpm.backward()\n",
        "        optimizer1.step()\n",
        "        ddpm_out = x_hat, down, up, t\n",
        "\n",
        "        # --- Train Diff-E ---\n",
        "        optimizer2.zero_grad()\n",
        "        decoder_out, fc_out, z = diffe_model(x, ddpm_out)\n",
        "        #loss_gap = criterion(decoder_out, loss_ddpm.detach())\n",
        "        loss_decoder = F.l1_loss(decoder_out, x_hat.detach())\n",
        "        loss_c = criterion_class(fc_out, y)\n",
        "        z_proj = proj_head(z)\n",
        "        loss_supcon = supcon_loss(z_proj, y)\n",
        "        loss = alpha * loss_c + beta * loss_supcon + gamma * loss_decoder\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "\n",
        "        # --- Update EMA ---\n",
        "        ema_classifier.update()\n",
        "\n",
        "        # --- Logging (Wandb) ---\n",
        "        wandb.log({\n",
        "            \"train/batch_loss_decoder\": loss_decoder.item(),\n",
        "            \"train/batch_loss_supcon\": loss_supcon.item(),\n",
        "            \"train/batch_loss_c\": loss_c.item(),\n",
        "            \"train/batch_loss_total\": loss.item(),\n",
        "            \"train/learning_rate1\": scheduler1.get_last_lr()[0],\n",
        "            \"train/learning_rate2\": scheduler2.get_last_lr()[0]\n",
        "        })\n",
        "\n",
        "        # --- Accumulate Epoch Losses ---\n",
        "        total_loss_decoder += loss_decoder.item()\n",
        "        total_loss_supcon += loss_supcon.item()\n",
        "        total_loss_c += loss_c.item()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # --- Return Average Epoch Losses ---\n",
        "    num_batches = len(train_loader)\n",
        "    avg_losses = {\n",
        "        \"loss_decoder\": total_loss_decoder / num_batches,\n",
        "        \"loss_supcon\": total_loss_supcon / num_batches,\n",
        "        \"loss_c\": total_loss_c / num_batches,\n",
        "        \"loss_total\": total_loss / num_batches,\n",
        "    }\n",
        "    return avg_losses"
      ],
      "metadata": {
        "id": "HD7Twze2ntdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(diffe_model, ddpm_model, ema_classifier, dataloader,\n",
        "             criterion_recon, criterion_class, epoch, device, num_classes):\n",
        "    \"\"\"Evaluates the model on the provided dataloader, returning metrics and losses.\"\"\"\n",
        "    diffe_model.eval()\n",
        "    ddpm_model.eval()\n",
        "    ema_classifier.eval()\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    total_loss_supcon = 0.0\n",
        "    total_loss_decoder = 0.0\n",
        "    total_loss_c = 0.0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    alpha = 1\n",
        "    beta = min(1.0, epoch / 50) * 0.2\n",
        "    gamma = min(1.0, epoch / 100) * 0.05\n",
        "    supcon_loss = SupConLoss(temperature=0.07)\n",
        "    proj_head = ProjectionHead(input_dim=256, proj_dim=128).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.type(torch.LongTensor).to(device)\n",
        "\n",
        "            # DDPM forward pass\n",
        "            x_hat, down, up, noise, t = ddpm_model(x)\n",
        "            loss_ddpm_per_sample = criterion_recon(x_hat, x)\n",
        "            loss_ddpm = loss_ddpm_per_sample.mean()\n",
        "            ddpm_out = x_hat, down, up, t\n",
        "\n",
        "            # DiffE forward pass\n",
        "            decoder_out, fc_out, z = diffe_model(x, ddpm_out)\n",
        "            #loss_gap = criterion_recon(decoder_out, loss_ddpm_per_sample).mean()\n",
        "\n",
        "            # Classification loss\n",
        "            y_hat = ema_classifier(diffe_model.encoder(x)[1])\n",
        "\n",
        "            loss_decoder = F.l1_loss(decoder_out, x_hat.detach())\n",
        "            loss_c = criterion_class(fc_out, y)\n",
        "            z_proj = proj_head(z)\n",
        "            loss_supcon = supcon_loss(z_proj, y)\n",
        "            loss = alpha * loss_c + beta * loss_supcon + gamma * loss_decoder\n",
        "\n",
        "            # For metrics calculation\n",
        "            y_hat_softmax = F.softmax(y_hat, dim=1)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "            all_preds.append(y_hat_softmax.detach().cpu())\n",
        "\n",
        "            # Accumulate losses\n",
        "            total_loss_decoder += loss_decoder.item()\n",
        "            total_loss_supcon += loss_supcon.item()\n",
        "            total_loss_c += loss_c.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    # Calculate average losses\n",
        "    num_batches = len(dataloader)\n",
        "    avg_losses = {\n",
        "        \"loss_decoder\": total_loss_decoder / num_batches,\n",
        "        \"loss_supcon\": total_loss_supcon / num_batches,\n",
        "        \"loss_c\": total_loss_c / num_batches,\n",
        "        \"loss_total\": total_loss / num_batches,\n",
        "    }\n",
        "\n",
        "    # Convert predictions and labels for metric calculation\n",
        "    all_labels = torch.cat(all_labels, dim=0).numpy()\n",
        "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
        "    pred_classes = all_preds.argmax(axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = (pred_classes == all_labels).mean()\n",
        "\n",
        "    # For multi-class metrics, handle potential warnings\n",
        "    try:\n",
        "        f1 = f1_score(all_labels, pred_classes, average=\"macro\", zero_division=0)\n",
        "        recall = recall_score(all_labels, pred_classes, average=\"macro\", zero_division=0)\n",
        "        precision = precision_score(all_labels, pred_classes, average=\"macro\", zero_division=0)\n",
        "        auc = roc_auc_score(all_labels, all_preds, average=\"macro\", multi_class=\"ovo\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Warning in metric calculation: {e}\")\n",
        "        f1, recall, precision, auc = 0.0, 0.0, 0.0, 0.0\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1\": f1,\n",
        "        \"recall\": recall,\n",
        "        \"precision\": precision,\n",
        "        \"auc\": auc,\n",
        "    }\n",
        "\n",
        "    return metrics, avg_losses"
      ],
      "metadata": {
        "id": "oQF2ld6knxDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wandb configuration\n",
        "config = {\n",
        "    # Model parameters\n",
        "    \"model_type\": \"DiffE-EEG\",\n",
        "    \"num_classes\": num_classes,\n",
        "    \"channels\": channels,\n",
        "    \"n_T\": n_T,\n",
        "    \"ddpm_dim\": ddpm_dim,\n",
        "    \"encoder_dim\": encoder_dim,\n",
        "    \"fc_dim\": fc_dim,\n",
        "\n",
        "    # Training parameters\n",
        "    \"epochs\": num_epochs,\n",
        "    \"train_batch_size\": batch_size_train,\n",
        "    \"test_batch_size\": batch_size_test,\n",
        "    \"seed\": seed,\n",
        "\n",
        "    # Optimizer parameters\n",
        "    \"optimizer\": \"AdamW\",\n",
        "    \"learning_rate_ddpm\": lr_ddpm,\n",
        "    \"learning_rate_diffe\": lr_diffe,\n",
        "    \"weight_decay\": weight_decay,\n",
        "\n",
        "    # Scheduler parameters\n",
        "    \"scheduler\": \"CosineAnnealingLR\",\n",
        "    \"scheduler_T_max\": num_epochs,\n",
        "    \"scheduler_eta_min\": 1e-7,\n",
        "\n",
        "    # EMA parameters\n",
        "    \"ema_beta\": 0.95,\n",
        "    \"ema_update_after_step\": 100,\n",
        "    \"ema_update_every\": 10\n",
        "}\n",
        "\n",
        "# Initialize wandb run\n",
        "run = wandb.init(\n",
        "    project=\"DiffE-EEG\",\n",
        "    config=config,\n",
        "    name=f\"diffE-FEIS-thinking\",\n",
        "    reinit=True  # For notebooks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "JtUpl9QOoEN0",
        "outputId": "79b4d9c9-29f0-4334-caeb-45e2300d31a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1UTmW6iNsuZDOK5pC8i70YZC-1owajRkF/IDL_Project/wandb/run-20250430_142041-6raarq10</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/parusha-pradhan-university-of-pittsburgh/DiffE-EEG/runs/6raarq10' target=\"_blank\">diffE-FEIS-thinking</a></strong> to <a href='https://wandb.ai/parusha-pradhan-university-of-pittsburgh/DiffE-EEG' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/parusha-pradhan-university-of-pittsburgh/DiffE-EEG' target=\"_blank\">https://wandb.ai/parusha-pradhan-university-of-pittsburgh/DiffE-EEG</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/parusha-pradhan-university-of-pittsburgh/DiffE-EEG/runs/6raarq10' target=\"_blank\">https://wandb.ai/parusha-pradhan-university-of-pittsburgh/DiffE-EEG/runs/6raarq10</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting training...\")\n",
        "epoch_progress = tqdm(range(num_epochs), desc=\"Epochs\", position=0)\n",
        "\n",
        "best_val_accuracy = 0.0\n",
        "\n",
        "for epoch in epoch_progress:\n",
        "    # --- Training ---\n",
        "    train_losses = train_epoch(\n",
        "        ddpm, diffe, fc_ema, train_loader,\n",
        "        optimizer1, optimizer2, scheduler1, scheduler2,\n",
        "        criterion, criterion_class, epoch, device, num_classes\n",
        "    )\n",
        "\n",
        "    # Step schedulers after full epoch\n",
        "    scheduler1.step()\n",
        "    scheduler2.step()\n",
        "\n",
        "    # --- Evaluation ---\n",
        "    epoch_progress.set_description(f\"Evaluating Epoch {epoch+1}/{num_epochs}\")\n",
        "    val_metrics, val_losses = evaluate(diffe, ddpm, fc_ema, validation_loader, criterion, criterion_class, epoch, device, num_classes)\n",
        "\n",
        "    # Update progress bar with metrics\n",
        "    epoch_progress.set_postfix({\n",
        "        'Train Loss': f\"{train_losses['loss_total']:.4f}\",\n",
        "        'Val Loss': f\"{val_losses['loss_total']:.4f}\",\n",
        "        'Val Acc': f\"{val_metrics['accuracy']:.4f}\",\n",
        "        'Val F1': f\"{val_metrics['f1']:.4f}\"\n",
        "    })\n",
        "\n",
        "    # --- Wandb Logging (Epoch Level) ---\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        # Training losses\n",
        "        \"train/epoch_loss_decoder\": train_losses['loss_decoder'],\n",
        "        \"train/epoch_loss_supcon\": train_losses['loss_supcon'],\n",
        "        \"train/epoch_loss_c\": train_losses['loss_c'],\n",
        "        \"train/epoch_loss_total\": train_losses['loss_total'],\n",
        "        # Validation losses\n",
        "        \"val/loss_decoder\": val_losses['loss_decoder'],\n",
        "        \"val/loss_supcon\": val_losses['loss_supcon'],\n",
        "        \"val/loss_c\": val_losses['loss_c'],\n",
        "        \"val/loss_total\": val_losses['loss_total'],\n",
        "        # Validation metrics\n",
        "        \"val/accuracy\": val_metrics['accuracy'],\n",
        "        \"val/f1_score\": val_metrics['f1'],\n",
        "        \"val/recall\": val_metrics['recall'],\n",
        "        \"val/precision\": val_metrics['precision'],\n",
        "        \"val/auc\": val_metrics['auc']\n",
        "    })\n",
        "\n",
        "    # --- Checkpoint Saving ---\n",
        "    current_accuracy = val_metrics['accuracy']\n",
        "    if current_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = current_accuracy\n",
        "        best_model_epoch = epoch + 1\n",
        "        epoch_progress.write(f\"*** New best validation accuracy: {best_val_accuracy:.4f} at epoch {epoch+1} ***\")\n",
        "        wandb.log({\"val/best_accuracy\": best_val_accuracy})\n",
        "\n",
        "        # Save the models\n",
        "        torch.save(diffe.state_dict(), os.path.join(models_path, f\"best_diffe_model_epoch{epoch+1}.pt\"))\n",
        "        torch.save(ddpm.state_dict(), os.path.join(models_path, f\"best_ddpm_model_epoch{epoch+1}.pt\"))\n",
        "        epoch_progress.write(f\"Models saved to {models_path}\")\n",
        "\n",
        "# --- End of Training ---\n",
        "print(\"Training finished.\")\n",
        "print(f\"Best validation accuracy achieved: {best_val_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebdrFxV1n3vE",
        "outputId": "8ee83631-c08d-41e2-b190-10fb62e413a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 1/100:   1%|          | 1/100 [00:16<26:28, 16.04s/it, Train Loss=2.7896, Val Loss=2.7753, Val Acc=0.0775, Val F1=0.0726]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.0775 at epoch 1 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:22<?, ?it/s]\n",
            "Evaluating Epoch 2/100:   2%|▏         | 2/100 [00:39<32:59, 20.20s/it, Train Loss=2.7787, Val Loss=2.7874, Val Acc=0.0735, Val F1=0.0728]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 3/100:   3%|▎         | 3/100 [00:54<28:56, 17.91s/it, Train Loss=2.7808, Val Loss=2.8149, Val Acc=0.0784, Val F1=0.0743]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.0784 at epoch 3 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 4/100:   4%|▍         | 4/100 [01:09<26:58, 16.86s/it, Train Loss=2.7784, Val Loss=2.8226, Val Acc=0.0810, Val F1=0.0801]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.0810 at epoch 4 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 5/100:   5%|▌         | 5/100 [01:24<25:43, 16.24s/it, Train Loss=2.7728, Val Loss=2.8513, Val Acc=0.0843, Val F1=0.0847]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.0843 at epoch 5 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 6/100:   6%|▌         | 6/100 [01:39<24:55, 15.91s/it, Train Loss=2.7636, Val Loss=2.8577, Val Acc=0.0947, Val F1=0.0937]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.0947 at epoch 6 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 7/100:   7%|▋         | 7/100 [01:55<24:23, 15.74s/it, Train Loss=2.7437, Val Loss=2.8666, Val Acc=0.1062, Val F1=0.1062]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.1062 at epoch 7 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:15<?, ?it/s]\n",
            "Evaluating Epoch 8/100:   8%|▊         | 8/100 [02:11<24:30, 15.98s/it, Train Loss=2.7059, Val Loss=2.8793, Val Acc=0.1135, Val F1=0.1128]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.1135 at epoch 8 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 9/100:   9%|▉         | 9/100 [02:27<23:55, 15.78s/it, Train Loss=2.6664, Val Loss=2.9068, Val Acc=0.1246, Val F1=0.1251]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.1246 at epoch 9 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:15<?, ?it/s]\n",
            "Evaluating Epoch 10/100:  10%|█         | 10/100 [02:43<23:55, 15.95s/it, Train Loss=2.6055, Val Loss=2.9081, Val Acc=0.1336, Val F1=0.1328]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.1336 at epoch 10 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 11/100:  11%|█         | 11/100 [02:58<23:22, 15.76s/it, Train Loss=2.5333, Val Loss=2.9238, Val Acc=0.1390, Val F1=0.1387]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.1390 at epoch 11 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 12/100:  12%|█▏        | 12/100 [03:14<22:54, 15.62s/it, Train Loss=2.4699, Val Loss=2.9169, Val Acc=0.1552, Val F1=0.1548]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.1552 at epoch 12 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 13/100:  13%|█▎        | 13/100 [03:29<22:28, 15.50s/it, Train Loss=2.3830, Val Loss=2.9392, Val Acc=0.1625, Val F1=0.1623]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.1625 at epoch 13 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 14/100:  14%|█▍        | 14/100 [03:44<22:05, 15.41s/it, Train Loss=2.2906, Val Loss=2.9770, Val Acc=0.1845, Val F1=0.1840]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.1845 at epoch 14 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 15/100:  15%|█▌        | 15/100 [04:01<22:32, 15.91s/it, Train Loss=2.2119, Val Loss=2.9717, Val Acc=0.1976, Val F1=0.1970]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.1976 at epoch 15 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 16/100:  16%|█▌        | 16/100 [04:17<22:09, 15.82s/it, Train Loss=2.1028, Val Loss=2.9733, Val Acc=0.2130, Val F1=0.2126]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.2130 at epoch 16 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 17/100:  17%|█▋        | 17/100 [04:32<21:38, 15.64s/it, Train Loss=2.0089, Val Loss=2.9906, Val Acc=0.2233, Val F1=0.2237]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.2233 at epoch 17 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 18/100:  18%|█▊        | 18/100 [04:47<21:13, 15.53s/it, Train Loss=1.9052, Val Loss=3.0251, Val Acc=0.2410, Val F1=0.2408]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.2410 at epoch 18 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 19/100:  19%|█▉        | 19/100 [05:03<20:50, 15.43s/it, Train Loss=1.8218, Val Loss=3.0501, Val Acc=0.2563, Val F1=0.2563]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.2563 at epoch 19 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 20/100:  20%|██        | 20/100 [05:18<20:29, 15.37s/it, Train Loss=1.7146, Val Loss=3.0552, Val Acc=0.2598, Val F1=0.2601]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.2598 at epoch 20 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 21/100:  21%|██        | 21/100 [05:33<20:10, 15.32s/it, Train Loss=1.6142, Val Loss=3.1106, Val Acc=0.2730, Val F1=0.2735]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.2730 at epoch 21 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 22/100:  22%|██▏       | 22/100 [05:48<19:52, 15.29s/it, Train Loss=1.5315, Val Loss=3.1057, Val Acc=0.2956, Val F1=0.2955]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.2956 at epoch 22 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 23/100:  23%|██▎       | 23/100 [06:04<19:47, 15.42s/it, Train Loss=1.4537, Val Loss=3.1165, Val Acc=0.3093, Val F1=0.3089]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.3093 at epoch 23 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 24/100:  24%|██▍       | 24/100 [06:19<19:35, 15.47s/it, Train Loss=1.3678, Val Loss=3.1939, Val Acc=0.3150, Val F1=0.3148]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.3150 at epoch 24 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 25/100:  25%|██▌       | 25/100 [06:35<19:16, 15.42s/it, Train Loss=1.3013, Val Loss=3.2896, Val Acc=0.3296, Val F1=0.3294]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.3296 at epoch 25 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 26/100:  26%|██▌       | 26/100 [06:50<18:56, 15.36s/it, Train Loss=1.2197, Val Loss=3.3003, Val Acc=0.3383, Val F1=0.3378]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.3383 at epoch 26 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 27/100:  27%|██▋       | 27/100 [07:05<18:36, 15.30s/it, Train Loss=1.1651, Val Loss=3.2999, Val Acc=0.3489, Val F1=0.3486]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.3489 at epoch 27 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 28/100:  28%|██▊       | 28/100 [07:20<18:18, 15.26s/it, Train Loss=1.1021, Val Loss=3.2950, Val Acc=0.3656, Val F1=0.3649]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.3656 at epoch 28 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 29/100:  29%|██▉       | 29/100 [07:36<18:02, 15.25s/it, Train Loss=1.0413, Val Loss=3.3389, Val Acc=0.3708, Val F1=0.3704]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.3708 at epoch 29 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 30/100:  30%|███       | 30/100 [07:51<17:45, 15.22s/it, Train Loss=0.9867, Val Loss=3.4086, Val Acc=0.3804, Val F1=0.3803]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.3804 at epoch 30 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 31/100:  31%|███       | 31/100 [08:06<17:36, 15.31s/it, Train Loss=0.9598, Val Loss=3.4663, Val Acc=0.3795, Val F1=0.3795]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 32/100:  32%|███▏      | 32/100 [08:22<17:25, 15.38s/it, Train Loss=0.9343, Val Loss=3.4506, Val Acc=0.3896, Val F1=0.3894]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.3896 at epoch 32 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 33/100:  33%|███▎      | 33/100 [08:37<17:10, 15.39s/it, Train Loss=0.8987, Val Loss=3.5214, Val Acc=0.3967, Val F1=0.3964]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.3967 at epoch 33 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 34/100:  34%|███▍      | 34/100 [08:52<16:53, 15.36s/it, Train Loss=0.8569, Val Loss=3.5180, Val Acc=0.4052, Val F1=0.4052]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.4052 at epoch 34 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 35/100:  35%|███▌      | 35/100 [09:08<16:33, 15.28s/it, Train Loss=0.8332, Val Loss=3.5557, Val Acc=0.4148, Val F1=0.4147]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.4148 at epoch 35 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 36/100:  36%|███▌      | 36/100 [09:23<16:14, 15.22s/it, Train Loss=0.8297, Val Loss=3.6261, Val Acc=0.4115, Val F1=0.4113]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 37/100:  37%|███▋      | 37/100 [09:38<15:56, 15.18s/it, Train Loss=0.7971, Val Loss=3.6199, Val Acc=0.4212, Val F1=0.4211]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.4212 at epoch 37 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 38/100:  38%|███▊      | 38/100 [09:53<15:38, 15.14s/it, Train Loss=0.7754, Val Loss=3.7102, Val Acc=0.4210, Val F1=0.4210]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 39/100:  39%|███▉      | 39/100 [10:08<15:24, 15.15s/it, Train Loss=0.7742, Val Loss=3.7755, Val Acc=0.4238, Val F1=0.4236]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.4238 at epoch 39 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 40/100:  40%|████      | 40/100 [10:23<15:13, 15.23s/it, Train Loss=0.7597, Val Loss=3.7862, Val Acc=0.4231, Val F1=0.4225]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 41/100:  41%|████      | 41/100 [10:39<15:04, 15.34s/it, Train Loss=0.7716, Val Loss=3.8323, Val Acc=0.4290, Val F1=0.4290]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.4290 at epoch 41 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 42/100:  41%|████      | 41/100 [10:54<15:04, 15.34s/it, Train Loss=0.7371, Val Loss=3.8443, Val Acc=0.4342, Val F1=0.4339]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.4342 at epoch 42 ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 42/100:  42%|████▏     | 42/100 [10:56<15:12, 15.73s/it, Train Loss=0.7371, Val Loss=3.8443, Val Acc=0.4342, Val F1=0.4339]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 43/100:  43%|████▎     | 43/100 [11:11<14:46, 15.54s/it, Train Loss=0.7600, Val Loss=3.8862, Val Acc=0.4342, Val F1=0.4338]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 44/100:  44%|████▍     | 44/100 [11:26<14:23, 15.41s/it, Train Loss=0.7536, Val Loss=3.8780, Val Acc=0.4424, Val F1=0.4425]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.4424 at epoch 44 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 45/100:  45%|████▌     | 45/100 [11:41<14:02, 15.31s/it, Train Loss=0.7180, Val Loss=3.9635, Val Acc=0.4403, Val F1=0.4403]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 46/100:  46%|████▌     | 46/100 [11:56<13:40, 15.20s/it, Train Loss=0.7420, Val Loss=4.0152, Val Acc=0.4419, Val F1=0.4419]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 47/100:  47%|████▋     | 47/100 [12:11<13:22, 15.14s/it, Train Loss=0.7553, Val Loss=3.9938, Val Acc=0.4405, Val F1=0.4402]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 48/100:  48%|████▊     | 48/100 [12:26<13:08, 15.17s/it, Train Loss=0.7317, Val Loss=4.0593, Val Acc=0.4396, Val F1=0.4395]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 49/100:  49%|████▉     | 49/100 [12:41<12:57, 15.25s/it, Train Loss=0.7320, Val Loss=4.1089, Val Acc=0.4415, Val F1=0.4413]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 50/100:  49%|████▉     | 49/100 [12:57<12:57, 15.25s/it, Train Loss=0.7580, Val Loss=4.1342, Val Acc=0.4457, Val F1=0.4458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.4457 at epoch 50 ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 50/100:  50%|█████     | 50/100 [12:58<13:05, 15.72s/it, Train Loss=0.7580, Val Loss=4.1342, Val Acc=0.4457, Val F1=0.4458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 51/100:  50%|█████     | 50/100 [13:13<13:05, 15.72s/it, Train Loss=0.7425, Val Loss=4.1606, Val Acc=0.4464, Val F1=0.4467]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.4464 at epoch 51 ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 51/100:  51%|█████     | 51/100 [13:15<13:05, 16.04s/it, Train Loss=0.7425, Val Loss=4.1606, Val Acc=0.4464, Val F1=0.4467]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 52/100:  52%|█████▏    | 52/100 [13:30<12:35, 15.74s/it, Train Loss=0.7537, Val Loss=4.2074, Val Acc=0.4365, Val F1=0.4363]\n",
            "Training:   0%|          | 0/620 [00:13<?, ?it/s]\n",
            "Evaluating Epoch 53/100:  53%|█████▎    | 53/100 [13:45<12:08, 15.50s/it, Train Loss=0.7387, Val Loss=4.2177, Val Acc=0.4412, Val F1=0.4413]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 54/100:  54%|█████▍    | 54/100 [14:00<11:45, 15.35s/it, Train Loss=0.7267, Val Loss=4.2022, Val Acc=0.4464, Val F1=0.4463]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 55/100:  55%|█████▌    | 55/100 [14:15<11:26, 15.25s/it, Train Loss=0.7265, Val Loss=4.2364, Val Acc=0.4452, Val F1=0.4455]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 56/100:  56%|█████▌    | 56/100 [14:31<11:14, 15.34s/it, Train Loss=0.7155, Val Loss=4.2696, Val Acc=0.4424, Val F1=0.4424]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 57/100:  56%|█████▌    | 56/100 [14:46<11:14, 15.34s/it, Train Loss=0.7145, Val Loss=4.2446, Val Acc=0.4478, Val F1=0.4477]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.4478 at epoch 57 ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 57/100:  57%|█████▋    | 57/100 [14:48<11:19, 15.80s/it, Train Loss=0.7145, Val Loss=4.2446, Val Acc=0.4478, Val F1=0.4477]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 58/100:  57%|█████▋    | 57/100 [15:02<11:19, 15.80s/it, Train Loss=0.6979, Val Loss=4.2864, Val Acc=0.4485, Val F1=0.4483]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.4485 at epoch 58 ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 58/100:  58%|█████▊    | 58/100 [15:04<11:09, 15.94s/it, Train Loss=0.6979, Val Loss=4.2864, Val Acc=0.4485, Val F1=0.4483]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 59/100:  59%|█████▉    | 59/100 [15:19<10:42, 15.67s/it, Train Loss=0.6968, Val Loss=4.2945, Val Acc=0.4514, Val F1=0.4514]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.4514 at epoch 59 ***\n",
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 60/100:  59%|█████▉    | 59/100 [15:34<10:42, 15.67s/it, Train Loss=0.6898, Val Loss=4.3016, Val Acc=0.4535, Val F1=0.4534]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** New best validation accuracy: 0.4535 at epoch 60 ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 60/100:  60%|██████    | 60/100 [15:36<10:40, 16.02s/it, Train Loss=0.6898, Val Loss=4.3016, Val Acc=0.4535, Val F1=0.4534]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved to saved_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 61/100:  61%|██████    | 61/100 [15:51<10:12, 15.71s/it, Train Loss=0.6968, Val Loss=4.3278, Val Acc=0.4481, Val F1=0.4484]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 62/100:  62%|██████▏   | 62/100 [16:06<09:56, 15.68s/it, Train Loss=0.6838, Val Loss=4.3575, Val Acc=0.4488, Val F1=0.4485]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 63/100:  63%|██████▎   | 63/100 [16:22<09:40, 15.69s/it, Train Loss=0.6920, Val Loss=4.3547, Val Acc=0.4483, Val F1=0.4484]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 64/100:  64%|██████▍   | 64/100 [16:37<09:20, 15.56s/it, Train Loss=0.6955, Val Loss=4.3562, Val Acc=0.4504, Val F1=0.4504]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 65/100:  65%|██████▌   | 65/100 [16:53<09:02, 15.51s/it, Train Loss=0.6792, Val Loss=4.3891, Val Acc=0.4518, Val F1=0.4517]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 66/100:  66%|██████▌   | 66/100 [17:08<08:46, 15.48s/it, Train Loss=0.7011, Val Loss=4.4099, Val Acc=0.4478, Val F1=0.4477]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 67/100:  67%|██████▋   | 67/100 [17:23<08:29, 15.43s/it, Train Loss=0.6700, Val Loss=4.4208, Val Acc=0.4499, Val F1=0.4497]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 68/100:  68%|██████▊   | 68/100 [17:39<08:11, 15.35s/it, Train Loss=0.6817, Val Loss=4.4396, Val Acc=0.4483, Val F1=0.4480]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 69/100:  69%|██████▉   | 69/100 [17:54<07:52, 15.25s/it, Train Loss=0.6684, Val Loss=4.4095, Val Acc=0.4516, Val F1=0.4517]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 70/100:  70%|███████   | 70/100 [18:09<07:39, 15.32s/it, Train Loss=0.6652, Val Loss=4.4287, Val Acc=0.4509, Val F1=0.4506]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 71/100:  71%|███████   | 71/100 [18:25<07:26, 15.40s/it, Train Loss=0.6600, Val Loss=4.4746, Val Acc=0.4473, Val F1=0.4473]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 72/100:  72%|███████▏  | 72/100 [18:40<07:08, 15.31s/it, Train Loss=0.6545, Val Loss=4.4604, Val Acc=0.4509, Val F1=0.4506]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 73/100:  73%|███████▎  | 73/100 [18:55<06:52, 15.27s/it, Train Loss=0.6704, Val Loss=4.4596, Val Acc=0.4528, Val F1=0.4528]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 74/100:  74%|███████▍  | 74/100 [19:10<06:35, 15.20s/it, Train Loss=0.6804, Val Loss=4.4863, Val Acc=0.4511, Val F1=0.4509]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 75/100:  75%|███████▌  | 75/100 [19:25<06:19, 15.17s/it, Train Loss=0.6710, Val Loss=4.5123, Val Acc=0.4528, Val F1=0.4527]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 76/100:  76%|███████▌  | 76/100 [19:40<06:04, 15.20s/it, Train Loss=0.6457, Val Loss=4.4799, Val Acc=0.4499, Val F1=0.4498]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 77/100:  77%|███████▋  | 77/100 [19:55<05:48, 15.15s/it, Train Loss=0.6538, Val Loss=4.4753, Val Acc=0.4471, Val F1=0.4471]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 78/100:  78%|███████▊  | 78/100 [20:10<05:32, 15.11s/it, Train Loss=0.6407, Val Loss=4.4877, Val Acc=0.4509, Val F1=0.4508]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 79/100:  79%|███████▉  | 79/100 [20:26<05:19, 15.19s/it, Train Loss=0.6514, Val Loss=4.5175, Val Acc=0.4490, Val F1=0.4489]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 80/100:  80%|████████  | 80/100 [20:41<05:06, 15.33s/it, Train Loss=0.6324, Val Loss=4.5078, Val Acc=0.4497, Val F1=0.4494]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 81/100:  81%|████████  | 81/100 [20:57<04:51, 15.37s/it, Train Loss=0.6446, Val Loss=4.5079, Val Acc=0.4511, Val F1=0.4510]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 82/100:  82%|████████▏ | 82/100 [21:12<04:36, 15.36s/it, Train Loss=0.6415, Val Loss=4.5188, Val Acc=0.4532, Val F1=0.4530]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 83/100:  83%|████████▎ | 83/100 [21:27<04:20, 15.32s/it, Train Loss=0.6327, Val Loss=4.5194, Val Acc=0.4511, Val F1=0.4511]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 84/100:  84%|████████▍ | 84/100 [21:43<04:04, 15.30s/it, Train Loss=0.6471, Val Loss=4.5668, Val Acc=0.4509, Val F1=0.4508]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 85/100:  85%|████████▌ | 85/100 [21:58<03:48, 15.23s/it, Train Loss=0.6493, Val Loss=4.5323, Val Acc=0.4481, Val F1=0.4479]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 86/100:  86%|████████▌ | 86/100 [22:13<03:33, 15.27s/it, Train Loss=0.6551, Val Loss=4.5312, Val Acc=0.4490, Val F1=0.4489]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 87/100:  87%|████████▋ | 87/100 [22:28<03:19, 15.32s/it, Train Loss=0.6457, Val Loss=4.5362, Val Acc=0.4490, Val F1=0.4488]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 88/100:  88%|████████▊ | 88/100 [22:44<03:05, 15.42s/it, Train Loss=0.6363, Val Loss=4.5410, Val Acc=0.4497, Val F1=0.4495]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 89/100:  89%|████████▉ | 89/100 [23:00<02:49, 15.45s/it, Train Loss=0.6388, Val Loss=4.5551, Val Acc=0.4497, Val F1=0.4496]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 90/100:  90%|█████████ | 90/100 [23:15<02:33, 15.36s/it, Train Loss=0.6393, Val Loss=4.5376, Val Acc=0.4490, Val F1=0.4487]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 91/100:  91%|█████████ | 91/100 [23:30<02:18, 15.34s/it, Train Loss=0.6581, Val Loss=4.5320, Val Acc=0.4490, Val F1=0.4487]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 92/100:  92%|█████████▏| 92/100 [23:45<02:02, 15.28s/it, Train Loss=0.6328, Val Loss=4.5537, Val Acc=0.4506, Val F1=0.4504]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 93/100:  93%|█████████▎| 93/100 [24:00<01:46, 15.25s/it, Train Loss=0.6373, Val Loss=4.5667, Val Acc=0.4488, Val F1=0.4485]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 94/100:  94%|█████████▍| 94/100 [24:16<01:31, 15.27s/it, Train Loss=0.6354, Val Loss=4.5453, Val Acc=0.4488, Val F1=0.4485]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 95/100:  95%|█████████▌| 95/100 [24:31<01:16, 15.24s/it, Train Loss=0.6543, Val Loss=4.5635, Val Acc=0.4485, Val F1=0.4482]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 96/100:  96%|█████████▌| 96/100 [24:46<01:01, 15.30s/it, Train Loss=0.6280, Val Loss=4.5724, Val Acc=0.4497, Val F1=0.4495]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 97/100:  97%|█████████▋| 97/100 [25:02<00:46, 15.37s/it, Train Loss=0.6364, Val Loss=4.5543, Val Acc=0.4490, Val F1=0.4488]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 98/100:  98%|█████████▊| 98/100 [25:17<00:30, 15.39s/it, Train Loss=0.6329, Val Loss=4.5777, Val Acc=0.4495, Val F1=0.4493]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 99/100:  99%|█████████▉| 99/100 [25:33<00:15, 15.33s/it, Train Loss=0.6338, Val Loss=4.5580, Val Acc=0.4495, Val F1=0.4493]\n",
            "Training:   0%|          | 0/620 [00:14<?, ?it/s]\n",
            "Evaluating Epoch 100/100: 100%|██████████| 100/100 [25:48<00:00, 15.48s/it, Train Loss=0.6317, Val Loss=4.5649, Val Acc=0.4497, Val F1=0.4495]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished.\n",
            "Best validation accuracy achieved: 0.4535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize EEG Signals"
      ],
      "metadata": {
        "id": "zor1QQBZDpY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_signals_grid(original, masked, reconstructed, sample_idxs, channel=0):\n",
        "    \"\"\"\n",
        "    Creates a grid figure showing for each sample:\n",
        "      Column 1: Signal Before (original)\n",
        "      Column 2: Signal Masked (noisy/masked)\n",
        "      Column 3: Signal After (reconstructed)\n",
        "    \"\"\"\n",
        "    num_samples = len(sample_idxs)\n",
        "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 4 * num_samples), squeeze=False)\n",
        "    for i, sample_idx in enumerate(sample_idxs):\n",
        "        orig_np = original[sample_idx, channel].detach().cpu().numpy()\n",
        "        masked_np = masked[sample_idx, channel].detach().cpu().numpy()\n",
        "        recon_np = reconstructed[sample_idx, channel].detach().cpu().numpy()\n",
        "        axes[i, 0].plot(orig_np, color='blue')\n",
        "        axes[i, 0].set_title(f\"Sample {sample_idx} - Signal Before\")\n",
        "        axes[i, 1].plot(masked_np, color='orange')\n",
        "        axes[i, 1].set_title(f\"Sample {sample_idx} - Signal Masked\")\n",
        "        axes[i, 2].plot(recon_np, color='green')\n",
        "        axes[i, 2].set_title(f\"Sample {sample_idx} - Signal After\")\n",
        "        for j in range(3):\n",
        "            axes[i, j].set_xlabel(\"Time\")\n",
        "            axes[i, j].set_ylabel(\"Amplitude\")\n",
        "    fig.tight_layout()\n",
        "    return fig"
      ],
      "metadata": {
        "id": "WJA4ZUzSDrgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_diffe_path = os.path.join(models_path, f\"best_diffe_model_epoch{best_model_epoch}.pt\")\n",
        "best_ddpm_path = os.path.join(models_path, f\"best_ddpm_model_epoch{best_model_epoch}.pt\")\n",
        "\n",
        "if os.path.exists(best_diffe_path) and os.path.exists(best_ddpm_path):\n",
        "    diffe.load_state_dict(torch.load(best_diffe_path))\n",
        "    ddpm.load_state_dict(torch.load(best_ddpm_path))\n",
        "    print(f\"Loaded best models from epoch {best_model_epoch}\")"
      ],
      "metadata": {
        "id": "ghAwyKZvbUpg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba07a7d-6735-4987-d7dd-b72030d11530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded best models from epoch 60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for x, _ in seen_test_loader:\n",
        "        x = x.to(device)\n",
        "        # Generate reconstruction\n",
        "        x_hat, down, up, noise, t = ddpm(x)\n",
        "\n",
        "        # Visualize multiple samples and channels\n",
        "        samples_to_visualize = min(3, x.size(0))\n",
        "        channels_to_visualize = min(3, x.size(1))\n",
        "\n",
        "        # Visualize each channel\n",
        "        for channel_idx in range(channels_to_visualize):\n",
        "            sample_idxs = list(range(samples_to_visualize))\n",
        "            fig = visualize_signals_grid(\n",
        "                x[:samples_to_visualize],\n",
        "                noise[:samples_to_visualize],  # Using the noise from the diffusion process\n",
        "                x_hat[:samples_to_visualize],\n",
        "                sample_idxs,\n",
        "                channel=channel_idx\n",
        "            )\n",
        "\n",
        "            wandb.log({f\"Final_EEG_Signals/Channel_{channel_idx}\": wandb.Image(fig)})\n",
        "            plt.close(fig)  # Close to free memory\n",
        "\n",
        "        # We only need one batch for visualization\n",
        "        break\n",
        "\n",
        "# --- Finish Wandb Run ---\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "KaqNm-wmDljT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e7dd4ad-e638-4211-a1fa-01b106f6038c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/batch_loss_c</td><td>████▇▇▇▅▅▅▃▃▄▄▃▃▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/batch_loss_decoder</td><td>█▅▄▇▅▇▃▄▄▃▄▄▃▄▂▃▃▅▃▃▄▂▃▄▂▄▂▂▄▄▃▂▁▃▂▃▂▂▂▄</td></tr><tr><td>train/batch_loss_supcon</td><td>▇█▆▆▄▂▁▅▂▄▃▄▃▅▅▃▄▅▄▅▅▃▅▄▅▃▆▄▄▄▅▄▆▄▅▃▅▃▁▃</td></tr><tr><td>train/batch_loss_total</td><td>█▇████▇▇█▅▃▂▃▁▁▂▁▁▂▁▁▂▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss_c</td><td>█████▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss_decoder</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss_supcon</td><td>█▇▄▄▄▃▃▅▃▃▄▃▃▃▂▂▂▃▂▂▂▁▂▂▂▄▂▂▃▂▂▂▁▂▂▁▂▂▃▂</td></tr><tr><td>train/epoch_loss_total</td><td>█████▇▇▇▆▆▅▄▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate1</td><td>██████▇▇▇▇▇▇▇▇▆▆▆▆▅▅▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▁▁▁▁▁</td></tr><tr><td>train/learning_rate2</td><td>██████▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val/accuracy</td><td>▁▁▂▂▂▄▄▄▅▆▇▇▇▇▇▇████████████████████████</td></tr><tr><td>val/auc</td><td>▁▁▂▂▃▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val/best_accuracy</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇████████</td></tr><tr><td>val/f1_score</td><td>▁▁▂▂▃▃▄▄▄▅▆▆▆▇▇▇▇▇██████████████████████</td></tr><tr><td>val/loss_c</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▂▃▃▄▄▅▆▆▆▆▆▇▇▇▇▇████████</td></tr><tr><td>val/loss_decoder</td><td>█▅▄▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/loss_supcon</td><td>█▆▅▅▆▃▃▄▂▄▂▃▃▂▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▁▁▁▂▂</td></tr><tr><td>val/loss_total</td><td>▁▁▁▁▂▂▂▂▂▂▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇███████████</td></tr><tr><td>val/precision</td><td>▁▁▁▁▁▂▃▄▄▄▅▆▆▇▇▇████████████████████████</td></tr><tr><td>val/recall</td><td>▁▁▁▁▂▃▄▄▅▅▇▇▇▇▇█████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>train/batch_loss_c</td><td>0.00417</td></tr><tr><td>train/batch_loss_decoder</td><td>0.09588</td></tr><tr><td>train/batch_loss_supcon</td><td>0</td></tr><tr><td>train/batch_loss_total</td><td>0.00892</td></tr><tr><td>train/epoch_loss_c</td><td>0.01044</td></tr><tr><td>train/epoch_loss_decoder</td><td>0.10224</td></tr><tr><td>train/epoch_loss_supcon</td><td>3.08118</td></tr><tr><td>train/epoch_loss_total</td><td>0.63174</td></tr><tr><td>train/learning_rate1</td><td>0.0</td></tr><tr><td>train/learning_rate2</td><td>0.0</td></tr><tr><td>val/accuracy</td><td>0.44971</td></tr><tr><td>val/auc</td><td>0.78153</td></tr><tr><td>val/best_accuracy</td><td>0.45347</td></tr><tr><td>val/f1_score</td><td>0.44948</td></tr><tr><td>val/loss_c</td><td>3.71435</td></tr><tr><td>val/loss_decoder</td><td>0.10235</td></tr><tr><td>val/loss_supcon</td><td>4.22761</td></tr><tr><td>val/loss_total</td><td>4.56494</td></tr><tr><td>val/precision</td><td>0.45018</td></tr><tr><td>val/recall</td><td>0.44972</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">diffE-FEIS-thinking</strong> at: <a href='https://wandb.ai/parusha-pradhan-university-of-pittsburgh/DiffE-EEG/runs/6raarq10' target=\"_blank\">https://wandb.ai/parusha-pradhan-university-of-pittsburgh/DiffE-EEG/runs/6raarq10</a><br> View project at: <a href='https://wandb.ai/parusha-pradhan-university-of-pittsburgh/DiffE-EEG' target=\"_blank\">https://wandb.ai/parusha-pradhan-university-of-pittsburgh/DiffE-EEG</a><br>Synced 5 W&B file(s), 3 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250430_142041-6raarq10/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on seen subjects\n",
        "seen_metrics, seen_losses = evaluate(diffe, ddpm, fc_ema, seen_test_loader,\n",
        "                                    criterion, criterion_class, epoch, device, num_classes)\n",
        "print(f\"Seen subjects test results: Accuracy={seen_metrics['accuracy']:.4f}, F1={seen_metrics['f1']:.4f}\")\n",
        "\n",
        "# Evaluate on unseen subjects\n",
        "unseen_metrics, unseen_losses = evaluate(diffe, ddpm, fc_ema, unseen_test_loader,\n",
        "                                        criterion, criterion_class, epoch, device, num_classes)\n",
        "print(f\"Unseen subjects test results: Accuracy={unseen_metrics['accuracy']:.4f}, F1={unseen_metrics['f1']:.4f}\")"
      ],
      "metadata": {
        "id": "S0v6uCv7QGLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d4968b-6a04-4e40-e01e-139e962cd760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seen subjects test results: Accuracy=0.4385, F1=0.4385\n",
            "Unseen subjects test results: Accuracy=0.0638, F1=0.0628\n"
          ]
        }
      ]
    }
  ]
}