{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmo5y6slBnx2"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIptPBvHBqBR",
        "outputId": "e6dce7c2-b104-40d9-e06c-ae2740028efd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install einops ema_pytorch mat73 numpy scikit_learn torch tqdm --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr2NsiZn8Vq2",
        "outputId": "37d03fdd-ce85-43b6-d857-626cffade8d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/IDL_Project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/\n",
        "%cd /content/drive/MyDrive/IDL_Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-UrbLS_NVg8-"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/IDL_Project/Diff-E')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gxtu9D4o91JK"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/diffe2023/Diff-E.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lECE57Y8BrqH"
      },
      "source": [
        "## Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ga3u6mv8Bt8h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from utils import zscore_norm, minmax_norm, EEGDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OuhF-wWECF9j"
      },
      "outputs": [],
      "source": [
        "def load_eeg_data(root_dir, subject_id, data_type='thinking', eeg_channels=None, window_size=256, step_size=128):\n",
        "    \"\"\"\n",
        "    Load EEG data from CSV files in the specified directory\n",
        "\n",
        "    Parameters:\n",
        "    root_dir (str): Path to the data_eeg folder\n",
        "    subject_id (str): Subject ID (e.g., '01', '02', etc.)\n",
        "    data_type (str): Type of data to load ('thinking', 'speaking', 'stimuli', etc.)\n",
        "    eeg_channels (list): List of EEG channel names to include\n",
        "    window_size (int): Size of the sliding window for epoching the data\n",
        "    step_size (int): Step size for the sliding window\n",
        "\n",
        "    Returns:\n",
        "    X (torch.Tensor): EEG data tensor of shape (n_samples, n_channels, n_timepoints)\n",
        "    Y (torch.Tensor): Labels tensor\n",
        "    \"\"\"\n",
        "    # Ensure subject_id is properly formatted\n",
        "    subject_id = str(subject_id).zfill(2)\n",
        "\n",
        "    # Define path to the subject's data\n",
        "    subject_dir = os.path.join(root_dir, subject_id)\n",
        "    file_path = os.path.join(subject_dir, f\"{data_type}.csv\")\n",
        "\n",
        "    # Check if file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
        "\n",
        "    # Read CSV data\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # If no EEG channels specified, use all available EEG channels\n",
        "    # Exclude non-EEG columns like 'Time:256Hz', 'Epoch', 'Label', 'Stage', 'Flag'\n",
        "    if eeg_channels is None:\n",
        "        non_eeg_cols = ['Time:256Hz', 'Epoch', 'Label', 'Stage', 'Flag']\n",
        "        eeg_channels = [col for col in df.columns if col not in non_eeg_cols]\n",
        "\n",
        "    # Extract EEG data and labels\n",
        "    eeg_data = df[eeg_channels].values  # shape: (n_samples, n_channels)\n",
        "\n",
        "    # Extract labels from the 'Label' column\n",
        "    if 'Label' in df.columns:\n",
        "        labels = df['Label'].values\n",
        "        unique_labels = np.unique(labels)\n",
        "        # Map labels to integers (0 to n_classes-1)\n",
        "        label_map = {label: i for i, label in enumerate(unique_labels)}\n",
        "        labels = np.array([label_map[label] for label in labels])\n",
        "    else:\n",
        "        # If no labels are available, create dummy labels\n",
        "        labels = np.zeros(len(eeg_data))\n",
        "\n",
        "    # Reshape data into epochs using sliding windows\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for i in range(0, len(eeg_data) - window_size + 1, step_size):\n",
        "        window_data = eeg_data[i:i+window_size, :].T  # Transpose to get (n_channels, n_timepoints)\n",
        "        window_label = labels[i + window_size // 2]  # Use the label from the middle of the window\n",
        "        X.append(window_data)\n",
        "        Y.append(window_label)\n",
        "\n",
        "    # Convert to torch tensors\n",
        "    X = torch.tensor(np.array(X), dtype=torch.float32)\n",
        "    Y = torch.tensor(np.array(Y), dtype=torch.long)\n",
        "\n",
        "    # Apply z-score normalization\n",
        "    X = zscore_norm(X)\n",
        "\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5z3S8XYRCQAE"
      },
      "outputs": [],
      "source": [
        "def load_multiple_subjects(root_dir, subject_ids, data_type='thinking'):\n",
        "    \"\"\"\n",
        "    Load data from multiple subjects and combine them\n",
        "\n",
        "    Parameters:\n",
        "    root_dir (str): Path to the data_eeg folder\n",
        "    subject_ids (list): List of subject IDs to load\n",
        "    data_type (str): Type of data to load\n",
        "\n",
        "    Returns:\n",
        "    X (torch.Tensor): Combined EEG data tensor\n",
        "    Y (torch.Tensor): Combined labels tensor\n",
        "    \"\"\"\n",
        "    all_X = []\n",
        "    all_Y = []\n",
        "\n",
        "    for subject_id in subject_ids:\n",
        "        try:\n",
        "            X, Y = load_eeg_data(root_dir, subject_id, data_type)\n",
        "            all_X.append(X)\n",
        "            all_Y.append(Y)\n",
        "            print(f\"Loaded data from subject {subject_id}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data from subject {subject_id}: {e}\")\n",
        "\n",
        "    # Combine data from all subjects\n",
        "    X_combined = torch.cat(all_X, dim=0)\n",
        "    Y_combined = torch.cat(all_Y, dim=0)\n",
        "\n",
        "    return X_combined, Y_combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Pd4s5C1qCTYe"
      },
      "outputs": [],
      "source": [
        "def get_dataloader(X, Y, batch_size, batch_size2, seed, shuffle=True):\n",
        "    \"\"\"\n",
        "    Split the data into training and testing sets and create DataLoader instances\n",
        "\n",
        "    Parameters:\n",
        "    X (torch.Tensor): EEG data tensor\n",
        "    Y (torch.Tensor): Labels tensor\n",
        "    batch_size (int): Batch size for training\n",
        "    batch_size2 (int): Batch size for testing\n",
        "    seed (int): Random seed for reproducibility\n",
        "    shuffle (bool): Whether to shuffle the data\n",
        "\n",
        "    Returns:\n",
        "    training_loader (DataLoader): DataLoader for training data\n",
        "    test_loader (DataLoader): DataLoader for test data\n",
        "    \"\"\"\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "        X, Y, test_size=0.2, shuffle=shuffle, stratify=Y, random_state=seed\n",
        "    )\n",
        "\n",
        "    training_set = EEGDataset(X_train, Y_train)\n",
        "    training_loader = DataLoader(training_set, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "    test_set = EEGDataset(X_test, Y_test)\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size2, shuffle=False)\n",
        "\n",
        "    return training_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3jQXynhvL4Ql"
      },
      "outputs": [],
      "source": [
        "def pad_channels(X, target_channels=16):\n",
        "    \"\"\"Pad EEG data tensor with zero channels to reach target_channels\"\"\"\n",
        "    batch_size, channels, seq_length = X.shape\n",
        "    if channels >= target_channels:\n",
        "        return X\n",
        "\n",
        "    # Create tensor with target_channels\n",
        "    padded_X = torch.zeros((batch_size, target_channels, seq_length), dtype=X.dtype)\n",
        "    # Copy original data to the first channels\n",
        "    padded_X[:, :channels, :] = X\n",
        "\n",
        "    return padded_X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5NbmcPeBdIs",
        "outputId": "d13c7617-0996-4eb7-af13-19c0a794281a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded data from subject 01\n",
            "Loaded data from subject 02\n",
            "Loaded data from subject 03\n",
            "Loaded data from subject 04\n",
            "Loaded data from subject 05\n",
            "Loaded data from subject 06\n",
            "Loaded data from subject 07\n",
            "Loaded data from subject 08\n",
            "Loaded data from subject 09\n",
            "Loaded data from subject 10\n",
            "Loaded data from subject 11\n",
            "Loaded data from subject 12\n",
            "Loaded data from subject 13\n",
            "Loaded data from subject 14\n",
            "Loaded data from subject 15\n",
            "Loaded data from subject 16\n",
            "Loaded data from subject 17\n",
            "Loaded data from subject 18\n",
            "Loaded data from subject 19\n",
            "Loaded data from subject 20\n",
            "Loaded data from subject 21\n"
          ]
        }
      ],
      "source": [
        "root_dir = \"data_eeg\"\n",
        "subject_ids = [str(i).zfill(2) for i in range(1, 22)]\n",
        "\n",
        "# Load thinking data from specified subjects\n",
        "X, Y = load_multiple_subjects(root_dir, subject_ids, data_type='thinking')\n",
        "X = pad_channels(X, target_channels=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kJ2xaYbRLcum"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "batch_size2 = 260\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_loader, test_loader = get_dataloader(X, Y, batch_size, batch_size2, seed, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAB7mv0rYtW9",
        "outputId": "31f82822-c5df-4ef2-dfa6-48791fefffb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of batches in train loader: 828\n",
            "Number of batches in test loader: 26\n",
            "Train Batch - Input shape: torch.Size([32, 16, 256]), Labels shape: torch.Size([32])\n",
            "Test Batch - Input shape: torch.Size([260, 16, 256]), Labels shape: torch.Size([260])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of batches in train loader: {len(train_loader)}\")\n",
        "print(f\"Number of batches in test loader: {len(test_loader)}\")\n",
        "\n",
        "for X_train, y_train in train_loader:\n",
        "    print(f\"Train Batch - Input shape: {X_train.shape}, Labels shape: {y_train.shape}\")\n",
        "    break\n",
        "\n",
        "for X_test, y_test in test_loader:\n",
        "    print(f\"Test Batch - Input shape: {X_test.shape}, Labels shape: {y_test.shape}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cM9P_X_D5or"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fv6aN9TvE1ko"
      },
      "outputs": [],
      "source": [
        "from models import *\n",
        "\n",
        "num_classes = 16\n",
        "channels = X.shape[1]\n",
        "\n",
        "n_T = 1000\n",
        "ddpm_dim = 128\n",
        "encoder_dim = 256\n",
        "fc_dim = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "08kpz17EE6nn"
      },
      "outputs": [],
      "source": [
        "ddpm_model = ConditionalUNet(in_channels=channels, n_feat=ddpm_dim).to(device)\n",
        "ddpm = DDPM(nn_model=ddpm_model, betas=(1e-6, 1e-2), n_T=n_T, device=device).to(device)\n",
        "encoder = Encoder(in_channels=channels, dim=encoder_dim).to(device)\n",
        "decoder = Decoder(in_channels=channels, n_feat=ddpm_dim, encoder_dim=encoder_dim).to(device)\n",
        "fc = LinearClassifier(encoder_dim, fc_dim, emb_dim=num_classes).to(device)\n",
        "diffe = DiffE(encoder, decoder, fc).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhmXU3HtMhlO",
        "outputId": "fca28545-331a-493e-fd84-59b9c6b81860"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ddpm size:  239174\n",
            "encoder size:  137475\n",
            "decoder size:  136466\n",
            "fc size:  404498\n"
          ]
        }
      ],
      "source": [
        "print(\"ddpm size: \", sum(p.numel() for p in ddpm.parameters()))\n",
        "print(\"encoder size: \", sum(p.numel() for p in encoder.parameters()))\n",
        "print(\"decoder size: \", sum(p.numel() for p in decoder.parameters()))\n",
        "print(\"fc size: \", sum(p.numel() for p in fc.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOZsp31dOYxx"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tNlCQ2V4Zdkb"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from ema_pytorch import EMA\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    top_k_accuracy_score,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "L8acAGf3b9-k"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, fc, generator, device):\n",
        "    labels = np.arange(0, 16)\n",
        "    Y = []\n",
        "    Y_hat = []\n",
        "    for x, y in generator:\n",
        "        x, y = x.to(device), y.type(torch.LongTensor).to(device)\n",
        "        encoder_out = encoder(x)\n",
        "        y_hat = fc(encoder_out[1])\n",
        "        y_hat = F.softmax(y_hat, dim=1)\n",
        "\n",
        "        Y.append(y.detach().cpu())\n",
        "        Y_hat.append(y_hat.detach().cpu())\n",
        "\n",
        "    # List of tensors to tensor to numpy\n",
        "    Y = torch.cat(Y, dim=0).numpy()  # (N, )\n",
        "    Y_hat = torch.cat(Y_hat, dim=0).numpy()  # (N, 13): has to sum to 1 for each row\n",
        "\n",
        "    # Accuracy and Confusion Matrix\n",
        "    accuracy = top_k_accuracy_score(Y, Y_hat, k=1, labels=labels)\n",
        "    f1 = f1_score(Y, Y_hat.argmax(axis=1), average=\"macro\", labels=labels)\n",
        "    recall = recall_score(Y, Y_hat.argmax(axis=1), average=\"macro\", labels=labels)\n",
        "    precision = precision_score(Y, Y_hat.argmax(axis=1), average=\"macro\", labels=labels)\n",
        "    auc = roc_auc_score(Y, Y_hat, average=\"macro\", multi_class=\"ovo\", labels=labels)\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1\": f1,\n",
        "        \"recall\": recall,\n",
        "        \"precision\": precision,\n",
        "        \"auc\": auc,\n",
        "    }\n",
        "    # df_cm = pd.DataFrame(confusion_matrix(Y, Y_hat.argmax(axis=1)))\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZJUYGayjM6JQ"
      },
      "outputs": [],
      "source": [
        "# Criterion\n",
        "criterion = nn.L1Loss()\n",
        "criterion_class = nn.MSELoss()\n",
        "\n",
        "# Define optimizer\n",
        "base_lr, lr = 9e-5, 1.5e-3\n",
        "optim1 = optim.RMSprop(ddpm.parameters(), lr=base_lr)\n",
        "optim2 = optim.RMSprop(diffe.parameters(), lr=base_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rAcHSnwpNkQu"
      },
      "outputs": [],
      "source": [
        "fc_ema = EMA(diffe.fc, beta=0.95, update_after_step=100, update_every=10,)\n",
        "\n",
        "step_size = 150\n",
        "scheduler1 = optim.lr_scheduler.CyclicLR(\n",
        "    optimizer=optim1,\n",
        "    base_lr=base_lr,\n",
        "    max_lr=lr,\n",
        "    step_size_up=step_size,\n",
        "    mode=\"exp_range\",\n",
        "    cycle_momentum=False,\n",
        "    gamma=0.9998,\n",
        ")\n",
        "scheduler2 = optim.lr_scheduler.CyclicLR(\n",
        "    optimizer=optim2,\n",
        "    base_lr=base_lr,\n",
        "    max_lr=lr,\n",
        "    step_size_up=step_size,\n",
        "    mode=\"exp_range\",\n",
        "    cycle_momentum=False,\n",
        "    gamma=0.9998,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT3fV0_eNs0m",
        "outputId": "9be02595-2f6c-4244-81e7-b89146b03c60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "Best accuracy: 30.62%: 100%|██████████| 500/500 [2:07:16<00:00, 15.27s/it]\n"
          ]
        }
      ],
      "source": [
        "# Train & Evaluate\n",
        "num_epochs = 500\n",
        "test_period = 1\n",
        "start_test = test_period\n",
        "alpha = 0.1\n",
        "\n",
        "best_acc = 0\n",
        "best_f1 = 0\n",
        "best_recall = 0\n",
        "best_precision = 0\n",
        "best_auc = 0\n",
        "\n",
        "with tqdm(total=num_epochs) as pbar:\n",
        "    for epoch in range(num_epochs):\n",
        "        ddpm.train()\n",
        "        diffe.train()\n",
        "\n",
        "        ############################## Train ###########################################\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.type(torch.LongTensor).to(device)\n",
        "            y_cat = F.one_hot(y, num_classes=16).type(torch.FloatTensor).to(device)\n",
        "            # Train DDPM\n",
        "            optim1.zero_grad()\n",
        "            x_hat, down, up, noise, t = ddpm(x)\n",
        "\n",
        "            loss_ddpm = F.l1_loss(x_hat, x, reduction=\"none\")\n",
        "            loss_ddpm.mean().backward()\n",
        "            optim1.step()\n",
        "            ddpm_out = x_hat, down, up, t\n",
        "\n",
        "            # Train Diff-E\n",
        "            optim2.zero_grad()\n",
        "            decoder_out, fc_out = diffe(x, ddpm_out)\n",
        "\n",
        "            loss_gap = criterion(decoder_out, loss_ddpm.detach())\n",
        "            loss_c = criterion_class(fc_out, y_cat)\n",
        "            loss = loss_gap + alpha * loss_c\n",
        "            loss.backward()\n",
        "            optim2.step()\n",
        "\n",
        "            # Optimizer scheduler step\n",
        "            scheduler1.step()\n",
        "            scheduler2.step()\n",
        "\n",
        "            # EMA update\n",
        "            fc_ema.update()\n",
        "\n",
        "        ############################## Test ###########################################\n",
        "        with torch.no_grad():\n",
        "            if epoch > start_test:\n",
        "                test_period = 1\n",
        "            if epoch % test_period == 0:\n",
        "                ddpm.eval()\n",
        "                diffe.eval()\n",
        "\n",
        "                metrics_test = evaluate(diffe.encoder, fc_ema, test_loader, device)\n",
        "\n",
        "                acc = metrics_test[\"accuracy\"]\n",
        "                f1 = metrics_test[\"f1\"]\n",
        "                recall = metrics_test[\"recall\"]\n",
        "                precision = metrics_test[\"precision\"]\n",
        "                auc = metrics_test[\"auc\"]\n",
        "\n",
        "                best_acc_bool = acc > best_acc\n",
        "                best_f1_bool = f1 > best_f1\n",
        "                best_recall_bool = recall > best_recall\n",
        "                best_precision_bool = precision > best_precision\n",
        "                best_auc_bool = auc > best_auc\n",
        "\n",
        "                if best_acc_bool:\n",
        "                    best_acc = acc\n",
        "                if best_f1_bool:\n",
        "                    best_f1 = f1\n",
        "                if best_recall_bool:\n",
        "                    best_recall = recall\n",
        "                if best_precision_bool:\n",
        "                    best_precision = precision\n",
        "                if best_auc_bool:\n",
        "                    best_auc = auc\n",
        "\n",
        "                description = f\"Best accuracy: {best_acc*100:.2f}%\"\n",
        "                pbar.set_description(description)\n",
        "        pbar.update(1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Mmo5y6slBnx2",
        "lECE57Y8BrqH",
        "-cM9P_X_D5or",
        "qOZsp31dOYxx"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
